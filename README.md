ğŸ­ AutoFactoryScope

Machine-Learningâ€“Powered Factory Layout Robot Detection System
C# WPF Frontend + Python ONNX Inference Backend

ğŸ“Œ Overview

AutoFactoryScope is an end-to-end system designed to automatically detect industrial robots on large-scale 2D factory layout images.

It combines:

YOLOv8-based object detection

ONNX-optimized inference backend (Python)

C# WPF desktop frontend

512Ã—512 tile-based processing pipeline for large factory drawings

Automatic robot counting + bounding box rendering

This project enables engineers to rapidly analyze factory layouts, count robot instances, and visualize ML-detected results.

âœ¨ Key Features
ğŸ”¹ 1. ML Detection Pipeline

Trained YOLO model (exported to ONNX)

512Ã—512 tiling with overlap for high-resolution layouts

Detection stitching & post-processing

Non-maximum suppression (NMS)

One-step inference pipeline via /infer endpoint

ğŸ”¹ 2. Python Backend

REST API (FastAPI or Flask)

ONNX Runtime for high-performance inference

Preprocessing, tiling, merging, visualization

JSON and image output

ğŸ”¹ 3. C# WPF Frontend

Clean UI for selecting an image

Sends image to backend via HTTP

Displays annotated output image

Shows metadata and robot counts

ğŸ”¹ 4. Modular Project Structure

models/ for ONNX weights

notebooks/ for EDA, training artifacts

backend/ for API + inference

frontend/ for WPF application

scripts/ for dev tools

ğŸ§  System Architecture
+------------------+
|    WPF Frontend  |
| (C#, .NET 8 WPF) |
+--------+---------+
         |
         | HTTP (POST multipart/form-data)
         v
+--------------------------+
|  Python Inference API    |
|  (FastAPI / Flask)       |
|    - Preprocess          |
|    - Tile (512x512)      |
|    - ONNX Inference      |
|    - Merge Detections    |
|    - Draw Boxes          |
+------------+-------------+
             |
             | PNG + JSON
             v
+--------------------------+
|  WPF Renders Result      |
+--------------------------+

ğŸ—‚ Repository Structure
AutoFactoryScope/
â”œâ”€ README.md
â”œâ”€ LICENSE
â”œâ”€ .gitignore
â”œâ”€ .gitattributes
â”œâ”€ .editorconfig
â”‚
â”œâ”€ .github/
â”‚  â”œâ”€ workflows/            # Continuous Integration (C# backend, Python backend)
â”‚  â””â”€ ISSUE_TEMPLATE/
â”‚     â”œâ”€ bug_report.md
â”‚     â””â”€ feature_request.md
â”‚
â”œâ”€ models/
â”‚  â”œâ”€ robot_detector.onnx   # Exported YOLO model
â”‚  â””â”€ label_map.json
â”‚
â”œâ”€ notebooks/
â”‚  â”œâ”€ 01_eda.ipynb
â”‚  â”œâ”€ 02_training_experiments.ipynb
â”‚  â””â”€ 03_inference_tests.ipynb
â”‚
â”œâ”€ data/
â”‚  â”œâ”€ samples/              # Example layout images
â”‚  â””â”€ README.md
â”‚
â”œâ”€ src/
â”‚  â”œâ”€ backend/
â”‚  â”‚  â””â”€ autofactoryscope_api/
â”‚  â”‚     â”œâ”€ main.py
â”‚  â”‚     â”œâ”€ inference.py
â”‚  â”‚     â”œâ”€ tiling.py
â”‚  â”‚     â”œâ”€ postprocess.py
â”‚  â”‚     â”œâ”€ visualize.py
â”‚  â”‚     â”œâ”€ config.py
â”‚  â”‚     â””â”€ requirements.txt
â”‚  â”‚
â”‚  â””â”€ frontend/
â”‚     â””â”€ AutoFactoryScope.Desktop/
â”‚        â”œâ”€ App.xaml
â”‚        â”œâ”€ MainWindow.xaml
â”‚        â”œâ”€ ViewModels/
â”‚        â”œâ”€ Services/
â”‚        â””â”€ Models/
â”‚
â””â”€ scripts/
   â”œâ”€ run_backend_dev.sh
   â”œâ”€ run_backend_dev.bat
   â””â”€ export_model_notes.md

ğŸš€ Getting Started
ğŸ”§ 1. Install Backend (Python)

Python 3.10+ recommended

cd src/backend/autofactoryscope_api
pip install -r requirements.txt


Run the server:

uvicorn autofactoryscope_api.main:app --reload --host 0.0.0.0 --port 8000


The API is now available at:

http://localhost:8000/docs

ğŸ–¥ï¸ 2. Run the WPF Frontend

Open:

src/frontend/AutoFactoryScope.Desktop/AutoFactoryScope.Desktop.sln


Build and run.

Default API endpoint:

http://localhost:8000/infer/image

ğŸ“¤ Inference API
POST /infer

Returns detection metadata (JSON)

POST /infer/image

Returns annotated PNG/JPEG with bounding boxes.

Request:

Content-Type: multipart/form-data
Field: image (file)


Response:

Annotated image

Detection metadata (robot count, bounding boxes)

ğŸ§ª Machine Learning Notes
âœ” Model

YOLOv8

Small architecture tuned for symbol-level detection

Trained via Google Colab

Hyperparameter tuning performed (model.tune())

âœ” Dataset

Entire factory layout PNGs

Preprocessing into 512Ã—512 tiles

Annotated using Roboflow

Custom deterministic train/val/test splitter

âœ” ONNX Export

Used for optimized CPU inference in production.

ğŸ›  Development Workflow
ğŸ”¥ Branching Strategy
main      â€“ protected, production-ready
develop   â€“ staging branch for stable work
feature/* â€“ individual contributor branches

ğŸ’¬ Pull Request Requirements

Code builds successfully

Linting passes

At least 1 approval

No direct commits to main

(If GitHub Team is not enabled, use the â€œDevelop branch onlyâ€ workflow.)

ğŸ”’ Security Practices

No force pushes to protected branches

Sensitive data (layout images from real factories) excluded

Notebook outputs sanitized before commit

ONNX model weights licensed internally

ğŸ“… Roadmap
Phase 1 (Current)

Backend inference pipeline

WPF integration

Core YOLO model

Phase 2

Add batch inference

Add robot-type classification

Add heatmap overlay mode (density map)

Phase 3

Multi-layout comparison

Integrate into enterprise workflow tools

Auto-report generation (PDF/Excel)

ğŸ¤ Contributing

Guidelines:

Feature branches only (feature/xyz)

PR required for all merges

Clean commit history (squash recommended)

Add tests for backend changes

Keep frontend code MVVM-aligned

ğŸ“„ License

MIT License (or your chosen license)
